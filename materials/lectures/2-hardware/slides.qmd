---
title: "Memory Hierarchy and Hardware"
format: 
  revealjs:
    chalkboard: true
editor: source
---
## Memory Hierarchy {background-image="/pics/ParallelHardware/MemHierarchy.png" background-size="80%" background-position="center"}

::: footer
[From Brown U, CSCI 0300 (2022)](https://cs.brown.edu/courses/csci0300/2022/assign/labs/lab4.html) CC-BY 4.0 License $\qquad$ **ns** = $10^{-9}$second $\quad$ **ms** = $10^{-3}$second
:::

## Memory Hierarchy {background-image="/pics/ParallelHardware/MemHierarchy.png" background-size="80%" background-position="center" background-opacity=0.2}

- Each level serves as cache for the level below  
- A data request checks each cache until satisfied
- Not finding an item generates a "cache miss"  
- A cache miss triggers a memory page swap from level below  
<br>

#### Large data sets do not fit in cache: contiguous memory access patterns speed up code

## Memory Hierarchy {background-image="/pics/ParallelHardware/MemHierarchy.png" background-size="80%" background-position="center" background-opacity=0.2}

## Titan{background-image="/pics/ParallelHardware/Titan.png" background-size="60%" background-position="bottom"}
### 27 PF
#### 2012-19

## Delta: (2022){background-image="/pics/ParallelHardware/delta_front_1.png" background-size="80%" background-position="center"}
### 8 PF

## Delta: (2022){background-image="/pics/ParallelHardware/ncsa-delta-back.jpg" background-size="80%" background-position="center"}
### 8 PF

## Delta: (2022){background-image="/pics/ParallelHardware/delta-row.jpg" background-size="70%" background-position="center"}
### 8 PF

## Two (Three) Basic Concepts in Hardware {background-image="/pics/ParallelHardware/ParallelHardware1.png" background-size="80%" background-position="center"}

## Flynn's Taxonomy (1972) 

-   [*Single Instruction, Single Data (**SISD**):*]{style="color:green;"} scalar processor, serial program (old-style CPU)
-   [*Single Instruction, Multiple Data (**SIMD**):*]{style="color:green;"} vector processor, array processor (old-style GPU)
-   [*Multiple Instruction, Multiple Data (**MIMD**):*]{style="color:green;"} multiple cores in a single processor, multiple processors in a single computer, and multiple computers in a cluster (today's CPU and GPU, but each still leans to legacy)
-   [*Multiple Instruction, Single Data (**MISD**):*]{style="color:green;"} is not used much

## Three Processor Technology Streams {.smaller}

[**Computers:**]{style="color:green;"}  
- **Fast and general** computing  
<br>
  
[**Graphics:**]{style="color:green;"}  
- Lots of pixels with same independent operations  
- **Highly parallel and simple** processing  
<br>

[**Cellphones:**]{style="color:green;"}  
- Small devices  
- **Low power** operation  
<br>

[All three have matured into large cluster deployment]{style="color:green;"}

## Shared Memory Hardware {.smaller}

**CPU** - [Computer technology stream]{style="color:green;"}  
- One or two chips, each with multiple cores  
- Current high-end is 64 cores (e.g. AMD EPYC "Milan" on Delta)  
- Hosts operating system (OS)  

**GPU** - [Graphics technology stream]{style="color:green;"}  
- Excellent SIMD throughput 
- Separate memory, so "offloading" co-processor concept  
- Lower power requirements per core, lots of slow cores  
- Does not host OS  

**ARM CPU-GPU** - [Cellphone technology stream]{style="color:green;"}     
- A hybrid unified memory architecture  
- Low power requirements  
- Hosts OS  


#### [CPUs fast and versatile but limited parallelism]{style="color:green;"}  
#### [GPUs slower and less versatile but extreme parallelism (4x+ cores)]{style="color:green;"}  

## UMA and NUMA

#### Uniform memory access

- A typical multicore CPU chip

#### Non-Uniform memory access

- A larger collection of multicore chips with hardware/software enabled global memory access
- Some memory is closer than other memory
  - More complex cache strategies

## Two (Three) Basic Concepts in Hardware {background-image="/pics/ParallelHardware/ParallelHardware1.png" background-size="80%" background-position="center"}

## Two (Three) Basic Concepts in Hardware {background-image="/pics/ParallelHardware/ParallelHardware2.png" background-size="80%" background-position="center"}

## Two (Three) Basic Concepts in Hardware {background-image="/pics/ParallelHardware/ParallelHardware3.png" background-size="80%" background-position="center"}

##  {background-image="/pics/ParallelHardware/ParallelHardware4.png" background-size="80%" background-position="center"}

##  {background-image="/pics/ParallelHardware/ParallelHardware5.png" background-size="80%" background-position="center"}

##  {background-image="/pics/ParallelHardware/ParallelHardware6.png" background-size="80%" background-position="center"}

##  {background-image="/pics/ParallelHardware/ParallelHardware7.png" background-size="80%" background-position="center"}

##  {background-image="/pics/ParallelHardware/ParallelHardware8.png" background-size="80%" background-position="center"}

## Two (Three) Basic Concepts in Hardware {background-image="/pics/ParallelSoftware/ParallelSoftware1.png" background-size="80%" background-position="center"}

## (Two) Three Basic Concepts from Software Viewpoint {background-image="/pics/ParallelSoftware/ParallelSoftware2.png" background-size="80%" background-position="center"}

## Native Programming Mindset {background-image="/pics/ParallelSoftware/ParallelSoftware3.png" background-size="80%" background-position="center"}

## Native Programming Models and Tools {background-image="/pics/ParallelSoftware/ParallelSoftware4.png" background-size="80%" background-position="center"}

## 40 Years of Parallel Computing {background-image="/pics/ParallelSoftware/ParallelSoftware5.png" background-size="80%" background-position="center"}

## Last 20 years of Advances {background-image="/pics/ParallelSoftware/ParallelSoftware6.png" background-size="80%" background-position="center"}

## Distributed Programming Works in Shared Memory {background-image="/pics/ParallelSoftware/ParallelSoftware7.png" background-size="80%" background-position="center"}

## R Interfaces to Low-Level Native Tools {background-image="/pics/ParallelSoftware/ParallelSoftware8.png" background-size="80%" background-position="center"}

## `parallel::mclapply()` {background-image="/pics/ParallelSoftware/ParallelSoftware9.png" background-size="80%" background-position="center"}

<!--
## Parallel Programming Models {.smaller}

### Shared Memory Parallel  
-   **Unix fork:** fork a process and let the OS manage it  ([parallel pkg]{style="color:green;"})  
-   **Multithreading:** explicitly program parallel sections ([libraries]{style="color:green;"})  
-   **OpenMP:** give explicit hints to a compiler to make it parallel ([libraries]{style="color:green;"})

### Distributed Memory Parallel  
-   **Manager-workers:** most common in simple cases    
-   **Single program, multiple data (SPMD):** common on clusters ([pbdMPI pkg]{style="color:green;"}) 
-   **MapReduce:** common in customer processing, continuous services ([sparklyr pkg]{style="color:green;"})  
-   **Dataflow:** dependency graph directed, can involve all of the above <br><br>

#### [Largest codes use combination of SPMD, Dataflow, and Multithreading or OpenMP]{style="color:green;"}
#### [Unix fork more common in scripting languages like R and Python]{style="color:green;"}
-->