---
title: "Faster R for All Platforms, Including HPC Clusters"
format: 
  revealjs:
    chalkboard: true
editor: source
knitr: true
---

## Speeding up your R code  {.smaller}
### Serial solutions before parallel solutions  
- Any R code can be made faster  
  - High-level code == deep complexity   
  - Profile and improve code first  
  - Vectorize loops if possible  
  - Compute once if not changing  
  - Know when copies are made  
  - Reduce generality to speed up  
  - Access data contiguous order when possible  
  - Move kernels into compiled language, such as C/C++  

## Performance Profiling Tools  
`system.time()` is a basic R utility for timing expressions

```{r}
#| echo: true 
#| cache: true

x = matrix(rnorm(20000*750), nrow=20000, ncol=750)

system.time({xtx1 = t(x) %*% x})
system.time({xtx2 = crossprod(x)})
all.equal(xtx1, xtx2)
identical(xtx1, xtx2)
sessionInfo()
```
<br>

$X^TX$ is a symmetric matrix

## Performance Profiling Tools  
`system.time()` is a basic R utility for timing expressions

```{r}
#| echo: true 
#| cache: true
system.time({cx1 = cov(x)})
system.time({cx2 = crossprod(sweep(x, 2, colMeans(x)))/(nrow(x) - 1)})
all.equal(cx1, cx2)
```

 $Cov(X) = \frac{(X - {\bf 1}\bar{x})^T(X - {\bf 1}\bar{x})}{n - 1},$ where $\bar{x}$ is a row vector of column means of $X$ and $\bf 1$ is a column of 1s

## Performance Profiling Tools: `Rprof()`

Samples call stack at interval (default 0.02 second)

```{r}
#| echo: true
#| eval: false

## consider import title=fastR/profile.R
x = matrix(rnorm(10000*250), nrow=10000, ncol=250)
Rprof()
invisible(prcomp(x))
Rprof(NULL)
summaryRprof()

# $by.self
#                 self.time self.pct total.time total.pct
# "La.svd"             0.64    78.05       0.70     85.37
# "%*%"                0.06     7.32       0.06      7.32
# "aperm.default"      0.04     4.88       0.04      4.88
# "is.finite"          0.04     4.88       0.04      4.88
# "matrix"             0.04     4.88       0.04      4.88

# $by.total
#                  total.time total.pct self.time self.pct
# "prcomp.default"       0.82    100.00      0.00     0.00
# "prcomp"               0.82    100.00      0.00     0.00
# "svd"                  0.72     87.80      0.00     0.00
# "La.svd"               0.70     85.37      0.64    78.05
# "%*%"                  0.06      7.32      0.06     7.32
# ### output truncated by presenter

# $sample.interval
# [1] 0.02

# $sampling.time
# [1] 0.98
```

## Performance Profiling Tools: `Rprof()`

```{r}
#| eval: false
#| echo: true

## consider import fastR/profile.R
Rprof(interval=.99)
invisible(prcomp(x))
Rprof(NULL)
summaryRprof()

# $by.self
# [1] self.time  self.pct   total.time total.pct
# <0 rows> (or 0-length row.names)

# $by.total
# [1] total.time total.pct  self.time  self.pct
# <0 rows> (or 0-length row.names)

# $sample.interval
# [1] 0.99

# $sampling.time
# [1] 0
```

## Performance Profiling Tools: **rbenchmark**
### a package that easily benchmarks different functions

```{r}
#| echo: true

x = matrix(rnorm(1000*500), nrow=1000, ncol=500)

f = function(x) t(x) %*% x
g = function(x) crossprod(x)

library(rbenchmark)
benchmark(f(x), g(x))
```

::: notes
#   test replications elapsed relative
# 1 f(x)          100  64.153    2.063
# 2 g(x)          100  31.098    1.000
:::

## Profiling Summary
- Profile, profile, profile  
- Use `system.time()` to get a general sense of a method  
- Use **rbenchmark**'s `benchmark()` function to compare 2 methods
- Use `Rprof()` for more detailed profiling
- Other tools exist for more advanced applications (**pbdPAPI** and **pbdPROF** on GitHub/RBigData)

## Vectorizing

```{r}
#| echo: true

n = 1e5
x = seq(0, 1, length.out=n)
f = function(x) exp(x^3 + 2.5*x^2 + 12*x + 0.12)
y1 = numeric(n)

set.seed(12345)
system.time({
  for(i in seq_len(n))
    y1[i] = f(x[i]) + rnorm(1)
})

set.seed(12345)
system.time({
  y2 = f(x) + rnorm(n)
})

all.equal(y1, y2)
```

## Compute Once if not Changing

A is a very large matrix
```{.r code-line-numbers="2,7,9,10,12,17,19-21"}
for (i in seq_len(n)){
  Y = t(A) %*% Q
  Q = qr.Q(qr(Y))
  Y = A %*% Q
  Q = qr.Q(qr(Y))
}
```
Move the transpose outside the loop:
```{.r code-line-numbers="1,3"}
tA = t(A)
for (i in seq_len(n)){
  Y = tA %*% Q
  Q = qr.Q(qr(Y))
  Y = A %*% Q
  Q = qr.Q(qr(Y))
}
```

## Check that Code is Still Correct

```{.r code-line-numbers="7,16-19"}
for (i in seq_len(n)){
  Y = t(A) %*% Q
  Q = qr.Q(qr(Y))
  Y = A %*% Q
  Q = qr.Q(qr(Y))
}
Q1 = Q

tA = t(A)
for (i in seq_len(n)){
  Y = tA %*% Q
  Q = qr.Q(qr(Y))
  Y = A %*% Q
  Q = qr.Q(qr(Y))
}
Q2 = Q
all.equal(Q1, Q2)
identical(Q1, Q2)
```

## Example from a Real R Package on CRAN

```{.r code-line-numbers="4"}
# ...
while(i<=N){
  for(j in 1:i){
    d.k = as.matrix(x)[l==j,l==j]}
# ...
```
Convert to matrix outside the loop:
```{.r code-line-numbers="2,5"}
# ...
x.mat = as.matrix(x)
while(i<=N){
  for(j in 1:i){
    d.k = x.mat[l==j,l==j]
# ...
```
By changing just 1 line of code, performance of the main
method of the package improved **over 3.5x** !

## Preallocate lists and vectors Instead of Growing Them

```{r}
m = 1e3
n = 1e5
mat = matrix(runif(m*n), nrow = m)

system.time({
result1 = NULL
for(i in seq_len(n)) {
    newres = mean(mat[, i])
    result1 = c(result1, newres)
}
})

system.time({
result2 = vector("double", n)
for(i in seq_len(n)) {
    newres = mean(mat[, i])
    result2[i] = newres
}
})
all.equal(result1, result2)
```

## Memory Hierarchy Considerations with Matrices and data.frames

* R matrices are stored by columns
* R data.frames (lists) are stored by variables 

```{r}
memuse::memuse(mat)
```
- Columns contain contiguous data
- Rows are scattered across columns

### R, Julia, Matlab, and Fortran are column-major
### Python and C are row-major

## Favor contigous access to arrays and lists

```{r}
system.time({
result1 = vector("double", m)
for(i in seq_len(m)) {
    result1[i] = mean(mat[i, ])
}
})

system.time({tmat = t(mat)})
system.time({
result2 = vector("double", m)
for(i in seq_len(m)) {
    result2[i] = mean(tmat[, i])
}
})
all.equal(result1, result2)
```

## Programming Languages Hierarchy {.smaller}

- **High-level, Scripting Languages:** R, Python, ... 
  - Efficient for vectors, matrices, and arrays
  - Interpreted at runtime to run pre-compiled executables  

- **Mid-level, Compiled Languages:** C, C++, Fortran, ...
    - Fast enough for loops through elements of long vectors

  - Need compiling and linking to machine libraries before they run  
  - Still machine and operating system independent
  
- **Low-level, Machine code**
  - Hardware and operating system specific
  - Manipulating data between registers and memory hierarchies


## Incorporating C++ Code into R (Rcpp)

- Simplifies integrating C++ code with R
- Maps R objects (vectors, matrices, functions, environments, etc.) to C++ classes
- Code is compiled, linked, and loaded on the fly, or added via packages
- Appropriate when custom element-wise operations cannot be vectorized with R

#### Read Advanced R: [High performance functions with Rcpp](https://adv-r.hadley.nz/rcpp.html) by Hadley Wickham

