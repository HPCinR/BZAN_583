---
title: "Faster R for All Platforms, Including HPC Clusters"
format: 
  revealjs:
    chalkboard: true
editor: source
knitr: true
---

## Speeding up your R code  {.smaller}
### Serial solutions before parallel solutions  
- Any R code can be made faster  
  - High-level code == deep complexity   
  - Profile and improve code first  
  - Vectorize loops if possible  
  - Compute once if not changing  
  - Know when copies are made  
  - Reduce generality to speed up  
- Move kernels into compiled language, such as C/C++  
- Consider parallel computation (multicore and distriuted) only after the above   

## Profiling: Why Profile?  
- Because performance matters  
- Your bottlenecks may surprise you  
- One line of R code can touch a lot of data  
- Unlike compilers, R will not fix it for you  

::: notes

What is a compiler?

:::

## Performance Profiling Tools  
`system.time()` is a basic R utility for timing expressions

```{r}
#| echo: true 
#| cache: true

x <- matrix(rnorm(20000*750), nrow=20000, ncol=750)

system.time({xtx1 = t(x) %*% x})
system.time({xtx2 = crossprod(x)})
all.equal(xtx1, xtx2)
identical(xtx1, xtx2)
```
<br>

$X^TX$ is a symmetric matrix

## Performance Profiling Tools  
`system.time()` is a basic R utility for timing expressions

```{r}
#| echo: true 
#| cache: true

system.time({cx1 = cov(x)})
system.time({cx2 = crossprod(sweep(x, 2, colMeans(x)))/(nrow(x) - 1)})
all.equal(cx1, cx2)
```

 $Cov(X) = \frac{(X - {\bf 1}\bar{x})^T(X - {\bf 1}\bar{x})}{n - 1},$ where $\bar{x}$ is a row vector of column means of $X$ and $\bf 1$ is a column of 1s

## Performance Profiling Tools: `Rprof()`

Samples call stack at interval (default 0.02 second)

```{r}
#| echo: true
#| eval: false

## consider import title=fastR/profile.R
x <- matrix(rnorm(10000*250), nrow=10000, ncol=250)
Rprof()
invisible(prcomp(x))
Rprof(NULL)
summaryRprof()

# $by.self
#                 self.time self.pct total.time total.pct
# "La.svd"             0.64    78.05       0.70     85.37
# "%*%"                0.06     7.32       0.06      7.32
# "aperm.default"      0.04     4.88       0.04      4.88
# "is.finite"          0.04     4.88       0.04      4.88
# "matrix"             0.04     4.88       0.04      4.88

# $by.total
#                  total.time total.pct self.time self.pct
# "prcomp.default"       0.82    100.00      0.00     0.00
# "prcomp"               0.82    100.00      0.00     0.00
# "svd"                  0.72     87.80      0.00     0.00
# "La.svd"               0.70     85.37      0.64    78.05
# "%*%"                  0.06      7.32      0.06     7.32
# ### output truncated by presenter

# $sample.interval
# [1] 0.02

# $sampling.time
# [1] 0.98
```

## Performance Profiling Tools: `Rprof()`

```{r}
#| eval: false
#| echo: true

## consider import fastR/profile.R
Rprof(interval=.99)
invisible(prcomp(x))
Rprof(NULL)
summaryRprof()

# $by.self
# [1] self.time  self.pct   total.time total.pct
# <0 rows> (or 0-length row.names)

# $by.total
# [1] total.time total.pct  self.time  self.pct
# <0 rows> (or 0-length row.names)

# $sample.interval
# [1] 0.99

# $sampling.time
# [1] 0
```

## Performance Profiling Tools: **rbenchmark**
### a package that easily benchmarks different functions

```{r}
#| echo: true

x <- matrix(rnorm(10000*500), nrow=10000, ncol=500)

f <- function(x) t(x) %*% x
g <- function(x) crossprod(x)

library(rbenchmark)
benchmark(f(x), g(x))
```

::: notes
#   test replications elapsed relative
# 1 f(x)          100  64.153    2.063
# 2 g(x)          100  31.098    1.000
:::

## Profiling Summary
- Profile, profile, profile  
- Use `system.time()` to get a general sense of a method  
- Use **rbenchmark**'s `benchmark()` function to compare 2 methods
- Use `Rprof()` for more detailed profiling
- Other tools exist for more advanced applications (**pbdPAPI** and **pbdPROF** on GitHub/RBigData)

## Vectorizing

```{r}
#| echo: true

n <- 1e5
x <- seq(0, 1, length.out=n)
f <- function(x) exp(x^3 + 2.5*x^2 + 12*x + 0.12)
y1 <- numeric(n)

set.seed(12345)
system.time(
  for(i in 1:n)
    y1[i] <- f(x[i]) + rnorm(1)
)

set.seed(12345)
system.time(
  y2 <- f(x) + rnorm(n)
)

all.equal(y1, y2)
```

## Compute Once if not Changing

A is a very large matrix
```{.r code-line-numbers="2,7,9,10,12,17,19-21"}
for (i in 1:n){
  Y <- t(A) %*% Q
  Q <- qr.Q(qr(Y))
  Y <- A %*% Q
  Q <- qr.Q(qr(Y))
}
```
Move the transpose outside the loop:
```{.r code-line-numbers="1,3"}
tA <- t(A)
for (i in 1:n){
  Y <- tA %*% Q
  Q <- qr.Q(qr(Y))
  Y <- A %*% Q
  Q <- qr.Q(qr(Y))
}
```

## Check that Code is Still Correct

```{.r code-line-numbers="7,16-19"}
for (i in 1:n){
  Y <- t(A) %*% Q
  Q <- qr.Q(qr(Y))
  Y <- A %*% Q
  Q <- qr.Q(qr(Y))
}
Q1 = Q

tA <- t(A)
for (i in 1:n){
  Y <- tA %*% Q
  Q <- qr.Q(qr(Y))
  Y <- A %*% Q
  Q <- qr.Q(qr(Y))
}
Q2 = Q
all.equal(Q1, Q2)
identical(Q1, Q2)
```

## Example from a Real R Package on CRAN

```{.r code-line-numbers="4"}
# ...
while(i<=N){
  for(j in 1:i){
    d.k <- as.matrix(x)[l==j,l==j]}
# ...
```
Convert to matrix outside the loop:
```{.r code-line-numbers="2,5"}
# ...
x.mat <- as.matrix(x)
while(i<=N){
  for(j in 1:i){
    d.k <- x.mat[l==j,l==j]
# ...
```
By changing just 1 line of code, performance of the main
method of the package improved **over 3.5x** !

## Preallocate lists and vectors Instead of Growing Them

```{r}
n = 1e4
df = data.frame(x = runif(n), y = runif(n), z = runif(n),
                a = sample(c("A", "B", "C"), size = n, replace = TRUE))
head(df)
for(i in 1:n) {
    
}
```

```{r}
```

## Programming Languages Hierarchy {.smaller}

- **High-level, Scripting Languages:** R, Python, Lua, Ruby, ... 
  - Interpreted at runtime to run pre-compiled executables  

- **Mid-level, Compiled Languages:** C, C++, Fortran, ...
  - Need compiling and linking to machine libraries before they run  
  - Compiler converts to low-level building blocks and provides code optimizations
  - A linker links them to libraries of machine code
  
- **Low-level, Machine code**
  - Architecture and operating system specific

## Programming Languages Hierarchy {.smaller}

- **High-level, Scripting Languages:** R, Python, ... 
  - Large building blocks, often vectors, matrices, and arrays

- **Mid-level, Compiled Languages:** C, C++, Fortran, ...
  - Mid-size building blocks  
  - Fast enough for loops through elements of long vectors
  - Still machine and operating system independent
  
- **Low-level, Machine code**
  - Hardware and operating system specific
  - Manipulating data between registers and memory hierarchies


## Incorporating C++ Code into R (Rcpp)

- Simplifies integrating C++ code with R
- Maps R objects (vectors, matrices, functions, environments, etc.) to C++ classes
- Code is compiled, linked, and loaded on the fly, or added via packages
- Appropriate when custom element-wise operations cannot be vectorized with R

#### Read Advanced R: [High performance functions with Rcpp](http://adv-r.had.co.nz/Rcpp.html) by Hadley Wickham

